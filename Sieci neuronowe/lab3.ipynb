{"cells":[{"cell_type":"code","source":["!pip install mkl"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"y5QNOSAOpQme","executionInfo":{"status":"ok","timestamp":1647852203297,"user_tz":-60,"elapsed":4373,"user":{"displayName":"Damian Lewandowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17541558676680812959"}},"outputId":"0e6dd921-4402-4495-a37c-d794a012e10d"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: mkl in /usr/local/lib/python3.7/dist-packages (2019.0)\n","Requirement already satisfied: intel-openmp in /usr/local/lib/python3.7/dist-packages (from mkl) (2022.0.2)\n"]}]},{"cell_type":"code","execution_count":5,"metadata":{"collapsed":true,"colab":{"base_uri":"https://localhost:8080/"},"id":"q4kCJpnJpAFx","executionInfo":{"status":"error","timestamp":1647852411152,"user_tz":-60,"elapsed":12,"user":{"displayName":"Damian Lewandowski","photoUrl":"https://lh3.googleusercontent.com/a/default-user=s64","userId":"17541558676680812959"}},"outputId":"5c8abdee-3781-4bb2-9f61-498205a809c6"},"outputs":[{"output_type":"error","ename":"ModuleNotFoundError","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m<ipython-input-5-d4ef9a712e9b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mnumpy\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mmatplotlib\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpyplot\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mplt\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mmkl\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mmkl\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mset_num_threads\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m4\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'mkl'","","\u001b[0;31m---------------------------------------------------------------------------\u001b[0;32m\nNOTE: If your import is failing due to a missing package, you can\nmanually install dependencies using either !pip or !apt.\n\nTo view examples of installing some common dependencies, click the\n\"Open Examples\" button below.\n\u001b[0;31m---------------------------------------------------------------------------\u001b[0m\n"],"errorDetails":{"actions":[{"action":"open_url","actionText":"Open Examples","url":"/notebooks/snippets/importing_libraries.ipynb"}]}}],"source":["import numpy as np\n","import matplotlib.pyplot as plt\n","import mkl\n","\n","mkl.set_num_threads(4)\n","np.random.seed(1234)\n","\n","%matplotlib inline\n","%config InlineBackend.figure_format = 'retina'\n","plt.rcParams[\"figure.figsize\"] = [16, 9]"]},{"cell_type":"markdown","metadata":{"id":"QTe07xxEpAFz"},"source":["### Handy utility functions"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"NK-jqpvIpAF1"},"outputs":[],"source":["def append_ones(matrix):\n","    return np.concatenate((matrix, np.ones((matrix.shape[0], 1), dtype=np.float32)), axis=1)\n","\n","def zeros(*dims):\n","    return np.zeros(shape=tuple(dims), dtype=np.float32)\n","\n","def ones(*dims):\n","    return np.ones(shape=tuple(dims), dtype=np.float32)\n","\n","def rand(*dims):\n","    return np.random.rand(*dims).astype(np.float32)\n","\n","def chunks(seq, size):\n","    return (seq[pos:pos + size] for pos in range(0, len(seq), size))\n","\n","def tiles(examples):\n","    rows_count = examples.shape[0]\n","    cols_count = examples.shape[1]\n","    tile_height = examples.shape[2]\n","    tile_width = examples.shape[3]\n","    \n","    space_between_tiles = 2\n","    img_matrix = np.empty(shape=(rows_count * (tile_height + space_between_tiles) - space_between_tiles,  \n","                                 cols_count * (tile_width + space_between_tiles) - space_between_tiles))\n","    img_matrix.fill(np.nan)\n","\n","    for r in range(rows_count):\n","        for c in range(cols_count):\n","            x_0 = r * (tile_height + space_between_tiles)\n","            y_0 = c * (tile_width + space_between_tiles)\n","            img_matrix[x_0:x_0 + tile_height, y_0:y_0 + tile_width] = examples[r, c]\n","    \n","    plt.matshow(img_matrix, cmap='gray', interpolation='none')\n","    plt.axis('off')\n","    plt.show()"]},{"cell_type":"markdown","metadata":{"id":"EIW7rzktpAF2"},"source":["# MNIST dataset"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"3cQmFHDKpAF3"},"outputs":[],"source":["import mnist\n","digits = np.reshape(mnist.train_images()[:12*24], newshape=(12, 24, 28, 28))\n","tiles(digits)"]},{"cell_type":"markdown","metadata":{"id":"iNkFAkvRpAF3"},"source":["# Restricted Boltzmann Machine & Contrastive Divergence algorithm"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"3tA8QXjUpAF4"},"outputs":[],"source":["def sigmoid(matrix):\n","    return 1.0 / (1.0 + np.exp(-matrix))\n","\n","class Rbm:\n","    def __init__(self, visible_size, hidden_size, learning_rate):\n","        self.visible_size = visible_size\n","        self.hidden_size = hidden_size\n","        self.learning_rate = learning_rate\n","        \n","        self.reset()\n","        \n","    def reset(self):\n","        self.W = np.random.normal(scale=0.01,\n","                                  size=(self.visible_size+1, self.hidden_size+1)).astype(np.float32)\n","        self.W[:, -1] = 0.0\n","        self.W[-1, :] = 0.0"]},{"cell_type":"markdown","metadata":{"id":"U7_guGJ_pAF4"},"source":["## Algorytm Contrastive Divergence\n","\n","$\\newcommand{\\vect}[1]{\\mathbf{#1}}$\n","W sieci RBM gradient funkcji kosztu względem wag wyznaczamy zgodnie ze wzorem:\n","\n","$\\frac{\\delta}{\\delta w_{ij}} -\\log P(\\vect{v}) = -\\mathbf{E}[v_i h_j \\vert \\vect{v}] + \\mathbf{E}[v_i h_j]$\n","\n","#### Faza pozytywna - odpowiada za część $\\mathbf{E}[v_i h_j \\vert \\vect{v}]$\n","\n","Tą część gradientu wyznaczamy przez wyliczenie iloczynów $v_i h_j$ pomiędzy elementami wektora obserwacji ($v_i$) a prawdopodobieństwami aktywacji w warstwie ukrytej ($h_j$). Operację tą możemy zapisać w postaci zwektoryzowanej jako:\n","\n","$\\nabla_P = \\vect{v}^T\\sigma(\\vect{vW})$\n","\n","#### Faza negatywna - odpowiada za część $\\mathbf{E}[v_i h_j]$\n","\n","Rozpoczynamy od prawdopodobieństw aktywacji neuronów w warstwie ukrytej, które zostały wyznaczone w fazie pozytywnej. Na ich podstawie losujemy próbkę aktywacji w warstwie ukrytej:\n","\n","$\\vect{h} = \\sigma (\\vect{vW}) > [rand_1, rand_2, \\dots, rand_m]$\n","\n","Następnie losujemy próbkę aktywacji w warstwie widocznej:\n","\n","$\\vect{v}_1 = \\sigma (\\vect{hW}^T) > [rand_1, rand_2, \\dots, rand_n]$\n","\n","Aby wyznaczyć *fantazję* sieci RBM, powyższe próbki losujemy (naprzemiennie) $k$ razy (gdzie $k$ to parametr algorytmu CD-*k*):\n","\n","$\\vect{h}_{k-1} = \\sigma (\\vect{v}_{k-1}\\vect{W}) > [rand_1, rand_2, \\dots, rand_m]$, \n","$\\vect{v}_k = \\sigma (\\vect{h}_{k-1}\\vect{W}^T) > [rand_1, rand_2, \\dots, rand_n]$\n","\n","Część negatywną gradientu wyznaczamy poprzez wyliczenie iloczynów $v_{k_i} h_j$ pomiędzy elementami wektora *fantazji* RBM ($v_{k_i}$) a prawdopodobieństwami aktywacji w warstwie ukrytej wyliczonymi dla tejże *fantazji* ($h_j$). Operację tą możemy zapisać w postaci zwektoryzowanej jako:\n","\n","$\\nabla_N = \\vect{v}_k^T\\sigma(\\vect{v}_k\\vect{W})$\n","\n","\n","#### Aktualizacja macierzy wag RBM\n","\n","Uczymy stochastycznym spadkiem wzdłuż gradientu:\n","\n","$\\phi_{t+1} \\leftarrow \\phi_t - \\epsilon \\nabla$\n","\n","co dla gradientu RBM daje:\n","\n","$W_{t+1} \\leftarrow W_t + \\epsilon \\nabla_P - \\epsilon \\nabla_N$"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"9Lm2Z5GfpAF5"},"outputs":[],"source":["def cdk(rbm, minibatch, k=1):\n","    observations_count = minibatch.shape[0]\n","\n","    positive_visible = minibatch\n","    negative_visible = append_ones(zeros(observations_count, rbm.visible_size))\n","\n","    positive_hidden = append_ones(zeros(observations_count, rbm.hidden_size))\n","    negative_hidden = append_ones(zeros(observations_count, rbm.hidden_size))\n","\n","    raise Exception(\"Not implemented!\")"]},{"cell_type":"markdown","metadata":{"id":"C8Q1HH7opAF6"},"source":["### RBM reconstruction error"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"Q9CDCSMJpAF7"},"outputs":[],"source":["def reconstuction_error(rbm, minibatch):\n","    observations_count = minibatch.shape[0]\n","    visible = zeros(observations_count, rbm.visible_size)\n","    hidden = append_ones(zeros(observations_count, rbm.hidden_size))\n","\n","    raise Exception(\"Not implemented!\")\n","\n","    return error"]},{"cell_type":"markdown","metadata":{"id":"tEJz4LTfpAF7"},"source":["# RBM Training"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"uJ_YpGXopAF8"},"outputs":[],"source":["import time\n","\n","DATASET_SIZE = 20000 # 60000 for whole dataset\n","DIGIT_SIZE = 28\n","\n","VISIBLE_LAYER_SIZE = DIGIT_SIZE*DIGIT_SIZE\n","HIDDEN_LAYER_SIZE = 128\n","LEARNING_RATE = 0.1\n","\n","mnist_train = mnist.train_images().astype(np.float32) / 255.0\n","np.random.shuffle(mnist_train)\n","dataset = np.reshape(mnist_train[:DATASET_SIZE], newshape=(DATASET_SIZE, DIGIT_SIZE*DIGIT_SIZE))\n","dataset = append_ones(dataset)\n","\n","monitoring_indeces = np.random.choice(DATASET_SIZE, 256, replace=False)\n","monitoring_set = dataset[monitoring_indeces]\n","\n","rbm = Rbm(VISIBLE_LAYER_SIZE, HIDDEN_LAYER_SIZE, LEARNING_RATE)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"2mcABUdFpAF8"},"outputs":[],"source":["def draw_filters(rbm):\n","    filters = np.reshape(np.transpose(rbm.W)[:-1, :-1], newshape=(8, -1, 28, 28))\n","    filters = np.clip(filters, -1, 1)\n","    tiles(filters)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"A3v8gkMypAF8"},"outputs":[],"source":["draw_filters(rbm)"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"h62j3-5HpAF9"},"outputs":[],"source":["BATCH_SIZE = 128\n","EPOCHS_COUNT = 50\n","\n","def train_epoch(rbm, dataset):\n","    batches_limit = dataset.shape[0] / BATCH_SIZE\n","    for batch_idx, batch in enumerate(chunks(dataset, BATCH_SIZE)):\n","        cdk(rbm, batch)\n","        if batch_idx % round(batches_limit / 50) == 0: print(\"#\", end=\"\")\n","\n","rbm.reset()\n","for epoch in range(EPOCHS_COUNT):\n","    print(\"Epoch {}:\".format(epoch + 1),  end=\"\\t\")\n","    \n","    start_time = time.time()\n","    train_epoch(rbm, dataset)\n","    \n","    elapsed = time.time() - start_time\n","    error = reconstuction_error(rbm, monitoring_set)\n","    print(\"\\telapsed: {0:>2.2f}s, reconstruction error: {1:>2.2f}\".format(elapsed, error))\n","    \n","print(\"Training finished!\")"]},{"cell_type":"code","execution_count":null,"metadata":{"collapsed":true,"id":"3Dh-E5j4pAF9"},"outputs":[],"source":["draw_filters(rbm)"]}],"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.2"},"colab":{"name":"lab3.ipynb","provenance":[]}},"nbformat":4,"nbformat_minor":0}